{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b3d4765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b8a1c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the image\n",
    "def display_img(img):\n",
    "    #resize the image\n",
    "    img = cv2.resize(img,(1200,1000))\n",
    "    cv2.imshow('img',img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "#convert image to grayscales image\n",
    "def grayscale_cvt(img):\n",
    "    return cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29ef39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = glob.glob('../panoramic_images/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "02b3cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grayscale images\n",
    "#image_list = [cv2.imread(i,cv2.IMREAD_GRAYSCALE) for i in image_paths ]\n",
    "\n",
    "#color images\n",
    "image_list = [cv2.imread(i) for i in image_paths ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5646603",
   "metadata": {},
   "source": [
    "# SIFT features computation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0410a632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets calculate SIFT features for each image and store them in a dict along with image\n",
    "image_features = {}\n",
    "sift = cv2.SIFT_create()\n",
    "for (i,image) in enumerate(image_list):\n",
    "    keypoints,descriptors = sift.detectAndCompute(image,None)\n",
    "    image_features['frame'+str(i)] = [image,keypoints,descriptors]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "969f4e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['frame0',\n",
       " 'frame1',\n",
       " 'frame2',\n",
       " 'frame3',\n",
       " 'frame4',\n",
       " 'frame5',\n",
       " 'frame6',\n",
       " 'frame7',\n",
       " 'frame8',\n",
       " 'frame9',\n",
       " 'frame10',\n",
       " 'frame11']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(image_features.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "04f7fdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_features = image_features['frame10']\n",
    "img2_features = image_features['frame4']\n",
    "#display_img(img1_features[0])\n",
    "\n",
    "img1,kp1,desc1 = img1_features[0],img1_features[1],img1_features[2]\n",
    "img2,kp2,desc2 = img2_features[0],img2_features[1],img2_features[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6ebd85fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets visualize keypoints in our image\n",
    "#display_img(cv2.drawKeypoints(img1,kp1,None))\n",
    "#display_img(cv2.drawKeypoints(img2,kp2,None))#reference image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f101b5",
   "metadata": {},
   "source": [
    "# Feature Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c4a1de75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a brute force matcher object\n",
    "# It will find all of the matching keypoints on two images\n",
    "bf = cv2.BFMatcher_create(cv2.NORM_L1)\n",
    "\n",
    "# Find matching points\n",
    "matches = bf.knnMatch(desc1, desc2,k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4bf3fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Filter matches using the Lowe's ratio test\n",
    "ratio_thresh = 0.6\n",
    "good_matches = []\n",
    "for m,n in knn_matches:\n",
    "    if m.distance < ratio_thresh * n.distance:\n",
    "        good_matches.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eb7977b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Draw matches\n",
    "img_matches = np.empty((max(img1.shape[0], img2.shape[0]), img1.shape[1]+img2.shape[1], 3), dtype=np.uint8)\n",
    "cv2.drawMatches(img1, kp1, img2, kp2, good_matches, img_matches, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "#-- Show detected matches\n",
    "display_img(img_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ca8e77",
   "metadata": {},
   "source": [
    "# Homography estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e6a41fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_matches[0].queryIdx\n",
    "reference_pts = np.array([kp2[match.trainIdx].pt for match in good_matches],dtype = np.float32)\n",
    "query_pts     = np.array([kp1[match.queryIdx].pt for match in good_matches],dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7619bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "h,status = cv2.findHomography(query_pts,reference_pts,cv2.RANSAC,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d3bb9b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#warp original image into reference plane\n",
    "display_img(cv2.warpPerspective(img2,h,(img2.shape[0],img2.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc88584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
